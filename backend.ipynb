{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\patil\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\patil\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver-manager\n",
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'phones'...\n",
      "Found 9 leads.\n",
      "Leads saved to phone.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Your ScraperAPI key\n",
    "api_key = 'f4cd663744c6f7fe0dc07d891bc15497'  # Replace with your API key\n",
    "\n",
    "# Function to fetch the data through ScraperAPI\n",
    "def fetch_data_with_scraperapi(search_query):\n",
    "    target_url = f'https://www.google.com/search?q={search_query.replace(\" \", \"+\")}'\n",
    "    payload = { \n",
    "        'api_key': api_key,\n",
    "        'url': target_url\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.text  # Return the HTML content of the page\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to parse the HTML and extract business leads\n",
    "def parse_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    leads = []\n",
    "\n",
    "    # Extracting relevant business information from the search results\n",
    "    for result in soup.find_all(class_='tF2Cxc'):\n",
    "        title = result.find('h3').text if result.find('h3') else None\n",
    "        link = result.find('a')['href'] if result.find('a') else None\n",
    "        description = result.find(class_='VwiC3b').text if result.find(class_='VwiC3b') else None\n",
    "\n",
    "        if title and link:\n",
    "            leads.append({\n",
    "                'Business Name': title,\n",
    "                'Link': link,\n",
    "                'Description': description\n",
    "            })\n",
    "\n",
    "    return leads\n",
    "\n",
    "# Function to save leads to a CSV file\n",
    "def save_to_csv(leads, filename):\n",
    "    if leads:\n",
    "        df = pd.DataFrame(leads)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Leads saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No leads found to save.\")\n",
    "\n",
    "# Main function to execute the scraping process\n",
    "def main():\n",
    "    search_query = input(\"What would you like to scrape? \")  # Prompt user for search query\n",
    "    csv_filename = input(\"Enter the name for the CSV file (without .csv extension): \") + '.csv'  # Prompt user for CSV file name\n",
    "    \n",
    "    print(f\"Searching for '{search_query}'...\")\n",
    "    html_content = fetch_data_with_scraperapi(search_query)\n",
    "\n",
    "    if html_content:\n",
    "        leads = parse_html(html_content)\n",
    "        if leads:\n",
    "            print(f\"Found {len(leads)} leads.\")\n",
    "            save_to_csv(leads, csv_filename)\n",
    "        else:\n",
    "            print(\"No leads found.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve content from the target URL.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
